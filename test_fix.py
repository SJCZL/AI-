#!/usr/bin/env python3
"""
æµ‹è¯•è„šæœ¬ï¼šéªŒè¯ä¿®å¤åçš„LangChainè´¨æ£€åŠŸèƒ½
"""

import os
import sys
import json
from langchain_openai import ChatOpenAI
from langchain.prompts import ChatPromptTemplate

# æ·»åŠ å½“å‰ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, os.path.dirname(__file__))

def test_prompt_loading():
    """æµ‹è¯•prompt.txtæ–‡ä»¶åŠ è½½"""
    try:
        prompt_file_path = os.path.join(os.path.dirname(__file__), 'prompt.txt')
        with open(prompt_file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        print("âœ… prompt.txtæ–‡ä»¶åŠ è½½æˆåŠŸ")
        print(f"ğŸ“„ æ–‡ä»¶é•¿åº¦: {len(content)} å­—ç¬¦")
        print(f"ğŸ” å†…å®¹é¢„è§ˆ: {content[:200]}...")
        return True
    except Exception as e:
        print(f"âŒ prompt.txtæ–‡ä»¶åŠ è½½å¤±è´¥: {e}")
        return False

def test_create_qa_prompt():
    """æµ‹è¯•åˆ›å»ºè´¨æ£€æç¤ºæ¨¡æ¿"""
    try:
        # æ¨¡æ‹Ÿcreate_qa_promptå‡½æ•°
        try:
            prompt_file_path = os.path.join(os.path.dirname(__file__), 'prompt.txt')
            with open(prompt_file_path, 'r', encoding='utf-8') as f:
                system_template = f.read()
            print("âœ… ä½¿ç”¨prompt.txtä½œä¸ºç³»ç»Ÿæç¤ºè¯")
        except Exception as e:
            print(f"âš ï¸ ä½¿ç”¨é»˜è®¤æç¤ºè¯: {e}")
            system_template = "é»˜è®¤æç¤ºè¯"
        
        human_template = "è¯·åˆ†æä»¥ä¸‹é”€å”®å¯¹è¯ï¼š{conversation}"
        
        # åˆ›å»ºæç¤ºæ¨¡æ¿
        from langchain.prompts import ChatPromptTemplate
        prompt = ChatPromptTemplate.from_messages([
            ("system", system_template),
            ("human", human_template)
        ])
        
        # æµ‹è¯•æ ¼å¼åŒ–
        test_conversation = "è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•å¯¹è¯"
        messages = prompt.format_messages(conversation=test_conversation)
        
        print("âœ… æç¤ºæ¨¡æ¿åˆ›å»ºæˆåŠŸ")
        print(f"ğŸ“‹ æ¶ˆæ¯æ•°é‡: {len(messages)}")
        print(f"ğŸ” ç³»ç»Ÿæ¶ˆæ¯é•¿åº¦: {len(messages[0].content)} å­—ç¬¦")
        
        return True
        
    except Exception as e:
        print(f"âŒ æç¤ºæ¨¡æ¿åˆ›å»ºå¤±è´¥: {e}")
        return False

def test_llm_initialization():
    """æµ‹è¯•LLMåˆå§‹åŒ–"""
    try:
        # æ£€æŸ¥ç¯å¢ƒå˜é‡
        api_key = os.getenv("OPENAI_API_KEY") or os.getenv("DEEPSEEK_API_KEY")
        if not api_key:
            print("âš ï¸ æœªæ‰¾åˆ°APIå¯†é’¥ç¯å¢ƒå˜é‡ï¼Œè·³è¿‡LLMæµ‹è¯•")
            return True
            
        llm = ChatOpenAI(
            model="deepseek-chat",
            openai_api_key=api_key,
            openai_api_base="https://api.deepseek.com/v1",
            temperature=0.7,
            max_tokens=1000
        )
        print("âœ… LLMåˆå§‹åŒ–æˆåŠŸ")
        return True
        
    except Exception as e:
        print(f"âŒ LLMåˆå§‹åŒ–å¤±è´¥: {e}")
        return False

if __name__ == "__main__":
    print("ğŸ§ª å¼€å§‹æµ‹è¯•LangChainè´¨æ£€ä¿®å¤...")
    print("=" * 50)
    
    tests = [
        ("prompt.txtæ–‡ä»¶åŠ è½½", test_prompt_loading),
        ("æç¤ºæ¨¡æ¿åˆ›å»º", test_create_qa_prompt),
        ("LLMåˆå§‹åŒ–", test_llm_initialization),
    ]
    
    passed = 0
    total = len(tests)
    
    for test_name, test_func in tests:
        print(f"\nğŸ” æµ‹è¯•: {test_name}")
        if test_func():
            passed += 1
        else:
            print(f"   æµ‹è¯•å¤±è´¥")
    
    print("\n" + "=" * 50)
    print(f"ğŸ“Š æµ‹è¯•ç»“æœ: {passed}/{total} é€šè¿‡")
    
    if passed == total:
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼ä¿®å¤æˆåŠŸ")
    else:
        print("âš ï¸ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥é…ç½®")
