import streamlit as st
import pandas as pd
import json
import time
from typing import List, Dict, Any
import io
from concurrent.futures import ThreadPoolExecutor, as_completed
import re
import os
from langchain_openai import ChatOpenAI
from langchain.prompts import ChatPromptTemplate
from langchain.schema import HumanMessage, SystemMessage
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="âœ¨ LangChainæ™ºèƒ½è´¨æ£€åŠ©æ‰‹",
    page_icon="ğŸ¯",
    layout="wide",
    initial_sidebar_state="expanded"
)

# è‡ªå®šä¹‰CSSæ ·å¼
st.markdown("""
<style>
    /* å…¨å±€æ ·å¼ */
    .main {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        padding: 0;
    }
    
    /* æ ‡é¢˜æ ·å¼ */
    .main-title {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        font-size: 3rem;
        font-weight: 700;
        text-align: center;
        margin-bottom: 0.5rem;
    }
    
    .subtitle {
        text-align: center;
        color: #666;
        font-size: 1.2rem;
        margin-bottom: 2rem;
    }
    
    /* å¡ç‰‡æ ·å¼ */
    .metric-card {
        background: white;
        border-radius: 15px;
        padding: 1.5rem;
        box-shadow: 0 8px 32px rgba(0, 0, 0, 0.1);
        backdrop-filter: blur(10px);
        border: 1px solid rgba(255, 255, 255, 0.2);
        transition: transform 0.3s ease;
    }
    
    .metric-card:hover {
        transform: translateY(-5px);
    }
    
    /* æŒ‰é’®æ ·å¼ */
    .stButton > button {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        border: none;
        border-radius: 25px;
        padding: 0.75rem 2rem;
        font-weight: 600;
        transition: all 0.3s ease;
        box-shadow: 0 4px 15px rgba(102, 126, 234, 0.4);
    }
    
    .stButton > button:hover {
        transform: translateY(-2px);
        box-shadow: 0 8px 25px rgba(102, 126, 234, 0.6);
    }
    
    /* ä¾§è¾¹æ æ ·å¼ */
    .css-1d391kg {
        background: linear-gradient(180deg, #f8f9fa 0%, #e9ecef 100%);
    }
    
    /* æ•°æ®è¡¨æ ¼æ ·å¼ */
    .dataframe {
        border-radius: 10px;
        overflow: hidden;
        box-shadow: 0 4px 15px rgba(0, 0, 0, 0.1);
    }
    
    /* è¿›åº¦æ¡æ ·å¼ */
    .stProgress > div > div {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
    }
    
    /* é€‰æ‹©å™¨æ ·å¼ */
    .stSelectbox > div > div {
        border-radius: 10px;
        border: 2px solid #e9ecef;
        transition: border-color 0.3s ease;
    }
    
    .stSelectbox > div > div:hover {
        border-color: #667eea;
    }
    
    /* å¤šé€‰æ¡†æ ·å¼ */
    .stMultiSelect > div > div {
        border-radius: 10px;
        border: 2px solid #e9ecef;
    }
    
    /* æ»‘å—æ ·å¼ */
    .stSlider > div > div {
        color: #667eea;
    }
    
    /* å¡ç‰‡å®¹å™¨ */
    .card-container {
        display: grid;
        grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
        gap: 1.5rem;
        margin: 1rem 0;
    }
    
    /* åŠ¨ç”»æ•ˆæœ */
    @keyframes fadeIn {
        from { opacity: 0; transform: translateY(20px); }
        to { opacity: 1; transform: translateY(0); }
    }
    
    .fade-in {
        animation: fadeIn 0.5s ease-in;
    }
    
    /* çŠ¶æ€æŒ‡ç¤ºå™¨ */
    .status-indicator {
        display: inline-block;
        width: 12px;
        height: 12px;
        border-radius: 50%;
        margin-right: 8px;
    }
    
    .status-success {
        background: #28a745;
    }
    
    .status-warning {
        background: #ffc107;
    }
    
    .status-error {
        background: #dc3545;
    }
</style>
""", unsafe_allow_html=True)

# åˆå§‹åŒ–session state
if 'processed_data' not in st.session_state:
    st.session_state.processed_data = None
if 'processing_complete' not in st.session_state:
    st.session_state.processing_complete = False
if 'json_sections' not in st.session_state:
    st.session_state.json_sections = None
if 'selected_sections' not in st.session_state:
    st.session_state.selected_sections = []

# æ ‡é¢˜åŒºåŸŸ
st.markdown('<h1 class="main-title">âœ¨ LangChainæ™ºèƒ½è´¨æ£€åŠ©æ‰‹</h1>', unsafe_allow_html=True)
st.markdown('<p class="subtitle">åŸºäºLangChain + DeepSeek V3çš„æ™ºèƒ½é”€å”®å¯¹è¯è´¨æ£€åˆ†æå¹³å°</p>', unsafe_allow_html=True)

# è£…é¥°æ€§åˆ†éš”çº¿
st.markdown("---")

def initialize_llm(api_key: str, base_url: str = None) -> ChatOpenAI:
    """åˆå§‹åŒ–DeepSeekæ¨¡å‹"""
    try:
        llm = ChatOpenAI(
            model="deepseek-chat",
            openai_api_key=api_key,
            openai_api_base=base_url or "https://api.deepseek.com/v1",
            temperature=0.7,
            max_tokens=10000
        )
        return llm
    except Exception as e:
        st.error(f"âŒ æ¨¡å‹åˆå§‹åŒ–å¤±è´¥: {str(e)}")
        return None

def create_qa_prompt() -> ChatPromptTemplate:
    """åˆ›å»ºè´¨æ£€æç¤ºæ¨¡æ¿"""
    try:
        # è¯»å–prompt.txtæ–‡ä»¶å†…å®¹ä½œä¸ºç³»ç»Ÿæç¤ºè¯
        prompt_file_path = os.path.join(os.path.dirname(__file__), 'prompt.txt')
        with open(prompt_file_path, 'r', encoding='utf-8') as f:
            system_template = f.read()
    except Exception as e:
        st.error(f"âŒ è¯»å–prompt.txtæ–‡ä»¶å¤±è´¥: {str(e)}")
        # å¦‚æœè¯»å–å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤æç¤ºè¯
        system_template = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„é”€å”®å¯¹è¯è´¨æ£€ä¸“å®¶ã€‚è¯·åˆ†æä»¥ä¸‹é”€å”®å¯¹è¯ï¼Œå¹¶ä»å¤šä¸ªç»´åº¦è¿›è¡Œè´¨é‡è¯„ä¼°ã€‚

è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¿”å›ç»“æœï¼š
{
    "å¯¹è¯è´¨é‡é—®é¢˜": [],
    "é”€å”®è¿ç¦è¯é—®é¢˜": [],
    "ä¼˜ç§€é”€å”®è¯æœ¯": [],
    "æ•´ä½“è¯„ä¼°": {
        "å¯¹è¯æ€»è½®æ¬¡": "æ€»è½®æ¬¡æ•°",
        "é—®é¢˜è½®æ¬¡å æ¯”": "X%",
        "ä¼˜ç§€è¯æœ¯è½®æ¬¡å æ¯”": "X%",
        "æ€»ä½“è´¨é‡ç­‰çº§": "ä¼˜ç§€/è‰¯å¥½/ä¸€èˆ¬/å¾…æ”¹è¿›"
    }
}

è¯·ç¡®ä¿JSONæ ¼å¼æ­£ç¡®ï¼Œæ‰€æœ‰å­—æ®µéƒ½è¦åŒ…å«ã€‚"""
    
    human_template = """è¯·åˆ†æä»¥ä¸‹é”€å”®å¯¹è¯ï¼š

{conversation}

è¯·æä¾›è¯¦ç»†çš„è´¨æ£€åˆ†æç»“æœã€‚"""
    
    return ChatPromptTemplate.from_messages([
        ("system", system_template),
        ("human", human_template)
    ])

def analyze_conversation(llm: ChatOpenAI, conversation: str) -> str:
    try:
        prompt = create_qa_prompt()
        messages = prompt.format_messages(conversation=conversation)
        response = llm.invoke(messages)
        return response.content
    except Exception as e:
        # ä¸è¦è®¿é—® responseï¼Œç›´æ¥è¿”å›é”™è¯¯ä¿¡æ¯
        return f"âŒ åˆ†æå¤±è´¥: {str(e)}"

def extract_json_from_text(text: str) -> Dict[str, Any]:
    """ä»æ–‡æœ¬ä¸­æå–JSONæ•°æ®"""
    try:
        return json.loads(text)
    except:
        json_pattern = r'```json\s*({.*?})\s*```'
        match = re.search(json_pattern, text, re.DOTALL)
        if match:
            try:
                return json.loads(match.group(1))
            except:
                pass
        
        json_pattern = r'\{.*\}'
        match = re.search(json_pattern, text, re.DOTALL)
        if match:
            try:
                return json.loads(match.group())
            except:
                pass
    
    return {}

def get_json_sections(json_data: Dict[str, Any]) -> List[str]:
    """è·å–JSONä¸­çš„æ‰€æœ‰é¡¶çº§é”®å"""
    return list(json_data.keys())

def extract_section_content(json_data: Dict[str, Any], section: str) -> Any:
    """æå–æŒ‡å®šsectionçš„å†…å®¹"""
    return json_data.get(section, None)

def process_single_row(row_data, llm):
    """å¤„ç†å•è¡Œæ•°æ®"""
    idx, value = row_data
    if pd.isna(value) or str(value).strip() == "":
        return idx, "â­ï¸ ç©ºå€¼è·³è¿‡"
    
    result = analyze_conversation(llm, str(value))
    return idx, result

def process_batch_parallel(data: pd.DataFrame, column_name: str, llm: ChatOpenAI,
                          progress_bar=None, status_text=None, max_workers: int = 5) -> pd.DataFrame:
    """å¹¶è¡Œæ‰¹é‡å¤„ç†æ•°æ®"""
    total_rows = len(data)
    
    tasks = [(idx, value) for idx, value in enumerate(data[column_name])]
    results = [None] * total_rows
    completed = 0
    
    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        future_to_idx = {
            executor.submit(process_single_row, task, llm): task[0] 
            for task in tasks
        }
        
        for future in as_completed(future_to_idx):
            idx, result = future.result()
            results[idx] = result
            completed += 1
            
            if progress_bar:
                progress = completed / total_rows
                progress_bar.progress(progress)
            if status_text:
                status_text.text(f"ğŸ”„ å¤„ç†è¿›åº¦: {completed}/{total_rows}")
    
    result_df = data.copy()
    result_df['è´¨æ£€ç»“æœ'] = results
    
    return result_df

def process_batch(data: pd.DataFrame, column_name: str, llm: ChatOpenAI,
                 progress_bar=None, status_text=None) -> pd.DataFrame:
    """é¡ºåºæ‰¹é‡å¤„ç†æ•°æ®"""
    results = []
    total_rows = len(data)
    
    for idx, value in enumerate(data[column_name]):
        if pd.isna(value) or str(value).strip() == "":
            results.append("â­ï¸ ç©ºå€¼è·³è¿‡")
            continue
            
        result = analyze_conversation(llm, str(value))
        results.append(result)
        
        if progress_bar:
            progress = (idx + 1) / total_rows
            progress_bar.progress(progress)
        if status_text:
            status_text.text(f"ğŸ”„ å¤„ç†è¿›åº¦: {idx + 1}/{total_rows}")
        
        time.sleep(0.5)
    
    result_df = data.copy()
    result_df['è´¨æ£€ç»“æœ'] = results
    
    return result_df

# ä¾§è¾¹æ é…ç½®
with st.sidebar:
    st.markdown("### ğŸ”§ é…ç½®ä¸­å¿ƒ")
    
    with st.container():
        st.markdown("#### ğŸ”‘ DeepSeek APIé…ç½®")
        
        api_key = st.text_input(
            "DeepSeek APIå¯†é’¥",
            type="password",
            help="ä»DeepSeekå¹³å°è·å–çš„APIå¯†é’¥",
            placeholder="è¾“å…¥æ‚¨çš„DeepSeek APIå¯†é’¥..."
        )
        
        base_url = st.text_input(
            "APIåŸºç¡€URL (å¯é€‰)",
            value="https://api.deepseek.com/v1",
            help="DeepSeek APIç«¯ç‚¹ï¼Œé€šå¸¸ä¸éœ€è¦ä¿®æ”¹",
            placeholder="https://api.deepseek.com/v1"
        )
        
        # æµ‹è¯•è¿æ¥æŒ‰é’®
        if st.button("ğŸ”„ æµ‹è¯•è¿æ¥"):
            if api_key:
                with st.spinner("æµ‹è¯•è¿æ¥ä¸­..."):
                    try:
                        test_llm = initialize_llm(api_key, base_url)
                        if test_llm:
                            response = test_llm.invoke([HumanMessage(content="ä½ å¥½")])
                            st.success("âœ… è¿æ¥æˆåŠŸï¼")
                        else:
                            st.error("âŒ è¿æ¥å¤±è´¥")
                    except Exception as e:
                        st.error(f"âŒ è¿æ¥å¤±è´¥: {str(e)}")
            else:
                st.warning("âš ï¸ è¯·å…ˆè¾“å…¥APIå¯†é’¥")
    
    st.markdown("---")
    
    with st.container():
        st.markdown("#### ğŸ“ æ–‡ä»¶ç®¡ç†")
        uploaded_file = st.file_uploader(
            "é€‰æ‹©æ–‡ä»¶",
            type=['csv', 'xlsx', 'xls'],
            help="æ”¯æŒCSVã€Excelæ–‡ä»¶",
            label_visibility="collapsed"
        )

# ä¸»å†…å®¹åŒºåŸŸ
if uploaded_file is not None:
    try:
        # è¯»å–æ–‡ä»¶
        if uploaded_file.name.endswith('.csv'):
            df = pd.read_csv(uploaded_file)
        else:
            df = pd.read_excel(uploaded_file)
        
        # æ–‡ä»¶ä¿¡æ¯å±•ç¤º
        col1, col2, col3 = st.columns([2,1,1])
        with col1:
            st.success(f"âœ… æˆåŠŸåŠ è½½æ–‡ä»¶: **{uploaded_file.name}**")
        with col2:
            file_size = len(uploaded_file.getvalue()) / 1024
            st.info(f"ğŸ“Š æ–‡ä»¶å¤§å°: {file_size:.1f} KB")
        with col3:
            st.info(f"ğŸ“‹ æ•°æ®è¡Œæ•°: {len(df)}")
        
        # æ•°æ®é¢„è§ˆå¡ç‰‡
        with st.container():
            st.markdown("### ğŸ“Š æ•°æ®é¢„è§ˆ")
            st.dataframe(df.head(10), use_container_width=True)
        
        # é…ç½®åŒºåŸŸ
        col1, col2 = st.columns([2, 1])
        
        with col1:
            st.markdown("### ğŸ¯ å¤„ç†é…ç½®")
            columns = df.columns.tolist()
            selected_column = st.selectbox(
                "é€‰æ‹©è´¨æ£€åˆ—",
                columns,
                help="é€‰æ‹©åŒ…å«éœ€è¦è´¨æ£€æ–‡æœ¬çš„åˆ—"
            )
            
            # æ˜¾ç¤ºé€‰ä¸­åˆ—çš„ç¤ºä¾‹
            with st.expander("ğŸ“‹ æŸ¥çœ‹ç¤ºä¾‹æ•°æ®"):
                sample_data = df[selected_column].head()
                for i, text in enumerate(sample_data, 1):
                    st.markdown(f"**ç¬¬{i}è¡Œ:** {text}")
        
        with col2:
            st.markdown("### âš¡ æ€§èƒ½é…ç½®")
            use_parallel = st.checkbox("ğŸš€ å¯ç”¨å¹¶è¡Œå¤„ç†", value=True)
            max_workers = st.slider(
                "å¹¶å‘çº¿ç¨‹æ•°",
                min_value=1,
                max_value=10,
                value=3,
                help="åŒæ—¶å¤„ç†çš„APIè°ƒç”¨æ•°é‡ï¼Œå»ºè®®ä¸è¶…è¿‡5ä¸ª"
            )
            
            # æ€§èƒ½æç¤º
            with st.expander("â„¹ï¸ æ€§èƒ½æç¤º"):
                st.markdown("""
                - **é¡ºåºå¤„ç†**: æ¯è¡Œ0.5ç§’é—´éš”
                - **å¹¶è¡Œå¤„ç†**: 3çº¿ç¨‹çº¦æå‡2-3å€é€Ÿåº¦
                - **å»ºè®®**: æ ¹æ®APIé™æµè°ƒæ•´çº¿ç¨‹æ•°
                - **DeepSeeké™åˆ¶**: æ¯åˆ†é’Ÿæœ€å¤š20æ¬¡è°ƒç”¨
                """)
        
        # å¤„ç†æŒ‰é’®åŒºåŸŸ
        st.markdown("---")
        col1, col2, col3 = st.columns([1, 2, 1])
        with col2:
            if st.button("ğŸš€ å¼€å§‹æ™ºèƒ½è´¨æ£€", type="primary", use_container_width=True):
                if not api_key:
                    st.error("âŒ è¯·å…ˆè¾“å…¥DeepSeek APIå¯†é’¥")
                else:
                    with st.spinner("ğŸ”„ åˆå§‹åŒ–æ¨¡å‹..."):
                        llm = initialize_llm(api_key, base_url)
                        if llm is None:
                            st.error("âŒ æ¨¡å‹åˆå§‹åŒ–å¤±è´¥")
                        else:
                            progress_bar = st.progress(0)
                            status_text = st.empty()
                            
                            with st.spinner("ğŸ”„ æ­£åœ¨å¤„ç†æ•°æ®..."):
                                if use_parallel:
                                    processed_df = process_batch_parallel(
                                        df, 
                                        selected_column, 
                                        llm, 
                                        progress_bar, 
                                        status_text,
                                        max_workers
                                    )
                                else:
                                    processed_df = process_batch(
                                        df, 
                                        selected_column, 
                                        llm, 
                                        progress_bar, 
                                        status_text
                                    )
                            
                            st.session_state.processed_data = processed_df
                            st.session_state.processing_complete = True
                            st.success("âœ… å¤„ç†å®Œæˆï¼")
                            st.balloons()
                
    except Exception as e:
        st.error(f"âŒ æ–‡ä»¶è¯»å–å¤±è´¥: {str(e)}")

# ç»“æœå±•ç¤ºåŒºåŸŸ
if st.session_state.processing_complete and st.session_state.processed_data is not None:
    st.markdown("---")
    st.markdown("### ğŸ“‹ è´¨æ£€ç»“æœ")
    
    # ç»“æœç»Ÿè®¡å¡ç‰‡
    col1, col2, col3, col4 = st.columns(4)
    
    total_rows = len(st.session_state.processed_data)
    success_rows = len([r for r in st.session_state.processed_data['è´¨æ£€ç»“æœ'] 
                       if not str(r).startswith(('âŒ', 'âš ï¸', 'â­ï¸'))])
    
    with col1:
        st.metric("ğŸ“Š æ€»å¤„ç†è¡Œæ•°", total_rows)
    with col2:
        st.metric("âœ… æˆåŠŸå¤„ç†", success_rows)
    with col3:
        st.metric("âŒ å¤±è´¥è¡Œæ•°", total_rows - success_rows)
    with col4:
        st.metric("ğŸ“ˆ æˆåŠŸç‡", f"{(success_rows/total_rows)*100:.1f}%")
    
    # ç»“æœè¡¨æ ¼
    st.markdown("#### ğŸ“Š è¯¦ç»†ç»“æœ")
    st.dataframe(st.session_state.processed_data, use_container_width=True)
    
    # JSONå†…å®¹æå–åŠŸèƒ½
    st.markdown("### ğŸ“Š æ™ºèƒ½å†…å®¹æå–")
    
    all_json_data = []
    valid_rows = []
    
    for idx, row in st.session_state.processed_data.iterrows():
        result_text = str(row.get('è´¨æ£€ç»“æœ', ''))
        if result_text and not result_text.startswith(('âŒ', 'âš ï¸', 'â­ï¸')):
            json_data = extract_json_from_text(result_text)
            if json_data:
                all_json_data.append(json_data)
                valid_rows.append(idx)
    
    if all_json_data:
        all_sections = set()
        for json_data in all_json_data:
            all_sections.update(get_json_sections(json_data))
        
        if all_sections:
            st.markdown("#### ğŸ¯ é€‰æ‹©æå–å†…å®¹")
            
            selected_sections = st.multiselect(
                "é€‰æ‹©è¦æ•´ç†çš„JSONéƒ¨åˆ†ï¼š",
                sorted(all_sections),
                help="é€‰æ‹©è¦æå–å’Œæ•´ç†çš„JSONéƒ¨åˆ†"
            )
            
            if selected_sections:
                st.markdown("#### ğŸ“‹ æå–ç»“æœ")
                
                tabs = st.tabs(selected_sections)
                
                for i, section in enumerate(selected_sections):
                    with tabs[i]:
                        section_data = []
                        for idx, json_data in enumerate(all_json_data):
                            content = extract_section_content(json_data, section)
                            if content is not None:
                                if isinstance(content, list):
                                    for item in content:
                                        section_data.append({
                                            'åŸå§‹è¡Œå·': valid_rows[idx] + 1,
                                            'å†…å®¹': item
                                        })
                                else:
                                    section_data.append({
                                        'åŸå§‹è¡Œå·': valid_rows[idx] + 1,
                                            'å†…å®¹': content
                                        })
                        
                        if section_data:
                            df_section = pd.DataFrame(section_data)
                            st.dataframe(df_section, use_container_width=True)
                            
                            csv_data = df_section.to_csv(index=False)
                            st.download_button(
                                label=f"ğŸ“¥ ä¸‹è½½ {section}",
                                data=csv_data,
                                file_name=f"{section}.csv",
                                mime="text/csv",
                                key=f"download_{section}_{i}"
                            )
                        else:
                            st.info(f"ğŸ“­ {section} æš‚æ— æ•°æ®")
    
    # ä¸‹è½½åŒºåŸŸ
    st.markdown("### ğŸ“¥ ä¸‹è½½é€‰é¡¹")
    col1, col2, col3 = st.columns(3)
    
    with col1:
        csv = st.session_state.processed_data.to_csv(index=False)
        st.download_button(
            label="ğŸ“„ ä¸‹è½½å®Œæ•´CSV",
            data=csv,
            file_name="è´¨æ£€ç»“æœ.csv",
            mime="text/csv",
            use_container_width=True
        )
    
    with col2:
        output = io.BytesIO()
        with pd.ExcelWriter(output, engine='openpyxl') as writer:
            st.session_state.processed_data.to_excel(writer, index=False, sheet_name='è´¨æ£€ç»“æœ')
        excel_data = output.getvalue()
        
        st.download_button(
            label="ğŸ“Š ä¸‹è½½å®Œæ•´Excel",
            data=excel_data,
            file_name="è´¨æ£€ç»“æœ.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            use_container_width=True
        )
    
    with col3:
        if st.button("ğŸ”„ é‡æ–°å¤„ç†", use_container_width=True):
            st.session_state.processed_data = None
            st.session_state.processing_complete = False
            st.session_state.json_sections = None
            st.session_state.selected_sections = []
            st.rerun()

# åº•éƒ¨ä¿¡æ¯
st.markdown("---")
st.markdown("""
<div style='text-align: center; color: #666; padding: 2rem;'>
    <p>ğŸš€ <strong>LangChainæ™ºèƒ½è´¨æ£€åŠ©æ‰‹</strong> - è®©AIä¸ºæ‚¨çš„é”€å”®å¯¹è¯è´¨æ£€èµ‹èƒ½</p>
    <p style='font-size: 0.9rem; margin-top: 0.5rem;'>
        åŸºäºStreamlit + LangChain + DeepSeek V3æ„å»º | æ”¯æŒå¹¶è¡Œå¤„ç† | æ™ºèƒ½å†…å®¹æå–
    </p>
</div>
""", unsafe_allow_html=True)
